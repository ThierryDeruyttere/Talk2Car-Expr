{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talk2car import Talk2Car\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"\")\n",
    "\n",
    "csv_file = \"/media/thierry/First/datasets/Cityscapes_Gaze/descriptions_gaze.csv\"\n",
    "\n",
    "allPunct = [\"?\", \"!\", \"\\\\\", \"/\", \")\", \"(\", \".\", \",\", \";\", \":\"]\n",
    "def tokenize(text, ignoredPuncts=[\"?\", \"!\", \"\\\\\", \"/\", \")\", \"(\"],\n",
    "             keptPuncts=[\".\", \",\", \";\", \":\"], endPunct=[\">\", \"<\", \":\"], delim=\" \",\n",
    "             clean=False, replacelistPre=dict(), replacelistPost=dict()):\n",
    "    if clean:\n",
    "        for word in replacelistPre:\n",
    "            origText = text\n",
    "            text = text.replace(word, replacelistPre[word])\n",
    "            if (origText != text):\n",
    "                print(origText)\n",
    "                print(text)\n",
    "                print(\"\")\n",
    "        for punct in endPunct:\n",
    "            if text[-1] == punct:\n",
    "                print(text)\n",
    "                text = text[:-1]\n",
    "                print(text)\n",
    "                print(\"\")\n",
    "    for punct in keptPuncts:\n",
    "        text = text.replace(punct, delim + punct + delim)\n",
    "    for punct in ignoredPuncts:\n",
    "        text = text.replace(punct, \"\")\n",
    "    ret = text.lower().split(delim)\n",
    "    if clean:\n",
    "        origRet = ret\n",
    "        ret = [replacelistPost.get(word, word) for word in ret]\n",
    "        if origRet != ret:\n",
    "            print(origRet)\n",
    "            print(ret)\n",
    "    ret = [t for t in ret if t != \"\"]\n",
    "    return ret\n",
    "\n",
    "class T2C(object):\n",
    "    N_CLASSES = 23\n",
    "    CLASSES = ('animal','human.pedestrian.adult', 'human.pedestrian.child',\n",
    "                  'human.pedestrian.construction_worker', 'human.pedestrian.personal_mobility',\n",
    "                  'human.pedestrian.police_officer', 'human.pedestrian.stroller', 'human.pedestrian.wheelchair',\n",
    "                  'movable_object.barrier', 'movable_object.debris', 'movable_object.pushable_pullable',\n",
    "                  'movable_object.trafficcone', 'static_object.bicycle_rack', 'vehicle.bicycle',\n",
    "                  'vehicle.bus.bendy', 'vehicle.bus.rigid', 'vehicle.car', 'vehicle.construction','vehicle.emergency.ambulance',\n",
    "                  'vehicle.emergency.police', 'vehicle.motorcycle', 'vehicle.trailer', 'vehicle.truck')\n",
    "\n",
    "    MEAN = [123.68, 116.779, 103.939]   # R,G,B\n",
    "\n",
    "    label_to_id = dict(map(reversed, enumerate(CLASSES)))\n",
    "    id_to_label = dict(enumerate(CLASSES))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval ...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 35.1 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 9.7 seconds.\n",
      "======\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval ...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 34.9 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 10.2 seconds.\n",
      "======\n",
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval ...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 37.5 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 10.7 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t2c_train = Talk2Car(version=\"train\", dataroot=\"/export/home2/NoCsBack/hci/thierry/datasets/nuScenes/data/sets/nuscenes\")\n",
    "t2c_val = Talk2Car(version=\"val\", dataroot=\"/export/home2/NoCsBack/hci/thierry/datasets/nuScenes/data/sets/nuscenes\")\n",
    "t2c_test = Talk2Car(version=\"test\", dataroot=\"/export/home2/NoCsBack/hci/thierry/datasets/nuScenes/data/sets/nuscenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr_train = json.load(open(\"/cw/liir/NoCsBack/testliir/datasets/refer_expr/Talk2Car/talk2car_descriptions_train.json\", \"r\"))\n",
    "descr_val = json.load(open(\"/cw/liir/NoCsBack/testliir/datasets/refer_expr/Talk2Car/talk2car_descriptions_val.json\", \"r\"))\n",
    "descr_test = json.load(open(\"/cw/liir/NoCsBack/testliir/datasets/refer_expr/Talk2Car/talk2car_descriptions_test.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'The black car parked on the right side of the street.',\n",
       " 'attrs': ['right', 'black', 'parked', 'street'],\n",
       " 'img': 'train_20.jpg',\n",
       " 'bbox': [1003, 461, 239, 166],\n",
       " 'class': 'vehicle.car'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(descr_train.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add description to t2c\n",
    "def add_descr(ds, descrs):\n",
    "    for c in ds.commands:\n",
    "        if c.command_token not in descrs:\n",
    "           c.description_data = None\n",
    "        else:\n",
    "            c.description_data = descrs[c.command_token] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_descr(t2c_train, descr_train)\n",
    "add_descr(t2c_test, descr_test)\n",
    "add_descr(t2c_val, descr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scene token: f92422ed4b4e427194a4958ccf15709a,\n",
       "Frame token: c32d636e44604d77a1734386b3fe4a0d,\n",
       "Box:         label: nan, score: nan, xyz: [-13.49, 0.43, 59.28], wlh: [0.81, 0.73, 1.96], rot axis: [-0.41, -0.64, 0.65], ang(degrees): -134.51, ang(rad): -2.35, vel: nan, nan, nan, name: human.pedestrian.adult, token: None"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2c_train.commands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([((529, 458, 24, 41), '0183ed8a474f411f8a3394eb78df7838'),\n",
       "  ((805, 461, 116, 95), '74f9ebe0551245a4b8c75baa56c94650'),\n",
       "  ((1502, 453, 98, 70), '6ffbac85dc92440b863ab5ebccddb955'),\n",
       "  ((1330, 464, 197, 62), '23d94b18989b4585acd689b687e3be7d'),\n",
       "  ((1525, 451, 75, 76), '648702e2c9fd45e1a22cc1e4e93022b2'),\n",
       "  ((761, 461, 83, 67), 'b625a075f5d647238446796e606b971e')],\n",
       " label: nan, score: nan, xyz: [-13.49, 0.43, 59.28], wlh: [0.81, 0.73, 1.96], rot axis: [-0.41, -0.64, 0.65], ang(degrees): -134.51, ang(rad): -2.35, vel: nan, nan, nan, name: human.pedestrian.adult, token: None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = t2c_train.commands[0]\n",
    "sd_rec = c.t2c.get('sample_data', c.frame_token)\n",
    "_, boxes, camera_intrinsic = c.t2c.get_sample_data(sd_rec['token'])\n",
    "[(t2c_train._transform_3d_to_2d_bbox(bbox.corners(), camera_intrinsic), bbox.token) for bbox in boxes], c.box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'human.pedestrian.adult')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T2C.label_to_id[t2c_train.commands[0].box.name]+1, t2c_train.commands[0].box.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "out_dict = {\n",
    "    \"info\": {\"description\": \"Talk2Car\",\n",
    "             \"url\": \"\", \"version\": \"1.0\", \"year\": 2020,\n",
    "             \"contributor\": \"\", \"date_created\": \"\"},\n",
    "    \"images\": [],\n",
    "    \"licenses\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [{\"supercategory\": x.split(\".\")[0], \"id\": i+1, \"name\": x} for i,x in enumerate(T2C.CLASSES)],\n",
    "}\n",
    "imgs = {}\n",
    "anns = []\n",
    "pickled = []\n",
    "\n",
    "abs_path = \"/cw/liir/NoCsBack/testliir/datasets/refer_expr/Talk2Car/imgs/\"\n",
    "\n",
    "for command in t2c_train.commands + t2c_val.commands + t2c_test.commands:\n",
    "    if command.description_data is None: continue\n",
    "        \n",
    "    img_path = abs_path+command.description_data[\"img\"]\n",
    "    \n",
    "    name = command.description_data[\"img\"]\n",
    "    \n",
    "    if name not in imgs:\n",
    "        imgs[name] = {\"license\": 1, \"file_name\": name, \"coco_url\": img_path, \"height\": 900, \"width\": 1600,\n",
    "                      \"date_captured\": \"2013-11-21 23:06:41\",\n",
    "                      \"flickr_url\": img_path, \"id\": len(imgs)}\n",
    "\n",
    "    sd_rec = command.t2c.get('sample_data', command.frame_token)\n",
    "    _, boxes, camera_intrinsic = command.t2c.get_sample_data(sd_rec['token'])\n",
    "    \n",
    "    bbox = list(t2c_train._transform_3d_to_2d_bbox(command.box.corners(), camera_intrinsic))\n",
    "    ann_id = None\n",
    "    if bbox[2]  == 0 or bbox[3] == 0:\n",
    "        print(\"WHAT\")\n",
    "        print(bbox)\n",
    "        break\n",
    "        \n",
    "    box_2d = [(t2c_train._transform_3d_to_2d_bbox(bbox.corners(), camera_intrinsic), bbox) for bbox in boxes]\n",
    "    # Add all objects in the image to the file\n",
    "    for b in box_2d:\n",
    "        \n",
    "        if (b[0][2] == 0 or b[0][3] == 0 or b[0][2] < 10 or b[0][3] < 10) and not np.allclose(b[0], bbox):\n",
    "            continue\n",
    "        if np.allclose(b[0], bbox):\n",
    "            ann_id = len(out_dict[\"annotations\"])\n",
    "            \n",
    "        out_dict[\"annotations\"].append({\n",
    "                \"image_id\": imgs[name][\"id\"],\n",
    "                \"bbox\": b[0],\n",
    "                \"category_id\": T2C.label_to_id[b[1].name]+1,\n",
    "                \"id\": len(out_dict[\"annotations\"])\n",
    "            })\n",
    "      \n",
    "    if ann_id == None:\n",
    "        print([b[0] for b in box_2d])\n",
    "        print(bbox)\n",
    "        print(t2c_train._transform_3d_to_2d_bbox(command.box.corners(), camera_intrinsic))\n",
    "        print(\"Breaking!!!\")\n",
    "        break\n",
    "              \n",
    "    split = command.description_data[\"img\"].split(\"_\")[0]\n",
    "    descr = command.description_data[\"description\"]\n",
    "    pickled.append({'sent_ids': [len(pickled)], 'file_name': name,\n",
    "                    'ann_id': ann_id, 'ref_id': ann_id,\n",
    "                     'image_id': imgs[name][\"id\"], 'split': split, \n",
    "                    'sentences': [\n",
    "                        {'tokens': tokenize(descr), \n",
    "                         'raw': command.description_data[\"description\"],\n",
    "                         'sent_id': len(pickled), \n",
    "                         'sent': command.description_data[\"description\"]}\n",
    "                    ],\n",
    "                    'category_id': T2C.label_to_id[command.box.name]+1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 0, 'bbox': (529, 458, 24, 41), 'category_id': 2, 'id': 0},\n",
       " {'image_id': 0, 'bbox': (805, 461, 116, 95), 'category_id': 17, 'id': 1},\n",
       " {'image_id': 0, 'bbox': (1502, 453, 98, 70), 'category_id': 17, 'id': 2},\n",
       " {'image_id': 0, 'bbox': (1330, 464, 197, 62), 'category_id': 17, 'id': 3},\n",
       " {'image_id': 0, 'bbox': (1525, 451, 75, 76), 'category_id': 17, 'id': 4},\n",
       " {'image_id': 0, 'bbox': (761, 461, 83, 67), 'category_id': 17, 'id': 5},\n",
       " {'image_id': 1, 'bbox': (751, 485, 27, 31), 'category_id': 9, 'id': 6},\n",
       " {'image_id': 1, 'bbox': (686, 489, 59, 41), 'category_id': 9, 'id': 7},\n",
       " {'image_id': 1, 'bbox': (504, 505, 106, 63), 'category_id': 9, 'id': 8},\n",
       " {'image_id': 1, 'bbox': (47, 521, 79, 45), 'category_id': 9, 'id': 9}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict[\"annotations\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"animal\", \"human.pedestrian.adult\", \"human.pedestrian.child\", \"human.pedestrian.construction_worker\", \"human.pedestrian.personal_mobility\", \"human.pedestrian.police_officer\", \"human.pedestrian.stroller\", \"human.pedestrian.wheelchair\", \"movable_object.barrier\", \"movable_object.debris\", \"movable_object.pushable_pullable\", \"movable_object.trafficcone\", \"static_object.bicycle_rack\", \"vehicle.bicycle\", \"vehicle.bus.bendy\", \"vehicle.bus.rigid\", \"vehicle.car\", \"vehicle.construction\", \"vehicle.emergency.ambulance\", \"vehicle.emergency.police\", \"vehicle.motorcycle\", \"vehicle.trailer\", \"vehicle.truck\"]'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(list(T2C.CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_dict['images'] = list(imgs.values())\n",
    "json.dump(out_dict,\n",
    "          open(\"/export/home2/NoCsBack/hci/thierry/netapp_thierry/attribute-2017/dataset/anns/original/ref2/talk2car/instances.json\",\"w\"))\n",
    "pickle.dump(pickled, open(\"/export/home2/NoCsBack/hci/thierry/netapp_thierry/attribute-2017/dataset/anns/original/ref2/talk2car/refs(kul).p\",\"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}